{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Feature Engineering / Preprocessing Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline \n",
    "\n",
    "# Import Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Import Cross val & Tuning\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Import warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning - nyari model mana yg plg the best. mau cari degree yg plg bgs yg mana.  \n",
    "Hyperparameter: apa yg mau kt pake, degree nya brp aja  \n",
    "\n",
    "Cross validation - adanya data leak yg menyebabkan overfit. data dr train set bocor ke test set. makanya di kasi validasi sblm test set. br base nya di uji kpd test set.  \n",
    "ada mean & standard deviasi, default nya 5 fold, nyari best model\n",
    "\n",
    "Tuning:  dari hasil crossval di tune biar hasil after tuning lebih bgs\n",
    "* Grid search - contohnya kalo SVR: C, kernel, degree, gamma  \n",
    "contohnya banyakkin c, di panjangin nanti buat tiap parameter, test 1 1  \n",
    "* Random search: dari grid search td, di cari scr acak, jd g semua grid diambil, lebih cpt dr gridsearch  \n",
    "\n",
    "Pipeline: bikin pipa utk jadiin 1 semua yg .fit sm .transform, bs buat regresi jg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_ori = pd.read_csv('https://raw.githubusercontent.com/FTDS-learning-materials/phase-1/master/w1/P1W1D3AM%20-%20Feature%20Engineering%20-%20Part%201%20-%20Titanic.csv')\n",
    "df = df_ori.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check dataset -1\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statement >>> misal ada missing value, mari lihat jumlah dan persentase nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "PassengerId     0.0\n",
      "Survived        0.0\n",
      "Pclass          0.0\n",
      "Name            0.0\n",
      "Sex             0.0\n",
      "Age            20.0\n",
      "SibSp           0.0\n",
      "Parch           0.0\n",
      "Ticket          0.0\n",
      "Fare            0.0\n",
      "Cabin          77.0\n",
      "Embarked        0.0\n",
      "dtype: float64%\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(f'{round(df.isnull().mean()*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "personal note: ngetrain model semain byk data semakin byk belajar, jd lebih bgs kalo lebih byk data, jd jgn main asal drop missval. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "karena kebutuhan kt skrg utk bljr, jadi seluruh missval di drop aja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "PassengerId    0.0\n",
      "Survived       0.0\n",
      "Pclass         0.0\n",
      "Name           0.0\n",
      "Sex            0.0\n",
      "Age            0.0\n",
      "SibSp          0.0\n",
      "Parch          0.0\n",
      "Ticket         0.0\n",
      "Fare           0.0\n",
      "Cabin          0.0\n",
      "Embarked       0.0\n",
      "dtype: float64%\n"
     ]
    }
   ],
   "source": [
    "# Check after drop\n",
    "print(df.isnull().sum())\n",
    "print(f'{round(df.isnull().mean()*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data duplicate\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split num cat col\n",
    "X = df.drop(['Survived'], axis = 1)\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>718</td>\n",
       "      <td>2</td>\n",
       "      <td>Troutt, Miss. Edwina Celia \"Winnie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34218</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>E101</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>Harrison, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112059</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B94</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17482</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>C90</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenfield, Mr. William Bertram</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17759</td>\n",
       "      <td>63.3583</td>\n",
       "      <td>D10 D12</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "      <td>Hays, Miss. Margaret Bechstein</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C54</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                              Name  \\\n",
       "717          718       2               Troutt, Miss. Edwina Celia \"Winnie\"   \n",
       "263          264       1                             Harrison, Mr. William   \n",
       "710          711       1  Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")   \n",
       "97            98       1                   Greenfield, Mr. William Bertram   \n",
       "310          311       1                    Hays, Miss. Margaret Bechstein   \n",
       "\n",
       "        Sex   Age  SibSp  Parch    Ticket     Fare    Cabin Embarked  \n",
       "717  female  27.0      0      0     34218  10.5000     E101        S  \n",
       "263    male  40.0      0      0    112059   0.0000      B94        S  \n",
       "710  female  24.0      0      0  PC 17482  49.5042      C90        C  \n",
       "97     male  23.0      0      1  PC 17759  63.3583  D10 D12        C  \n",
       "310  female  24.0      0      0     11767  83.1583      C54        C  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train, tes, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=70) #randomstate untuk ngunci tiap running state nya sama\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saya berasumsi PassengerID, Name, dan Ticket itu korelasi dengan target nya rendah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection\n",
    "X_train.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)\n",
    "X_test.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "categorical: ['Sex', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# Split num col & cat col\n",
    "num_col = X_train.select_dtypes(exclude=['object']).columns.tolist()\n",
    "cat_col = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f'numerical: {num_col}')\n",
    "print(f'categorical: {cat_col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statement contoh >>> setelah berhasil memisahkan categorical & numerical column, skrg saya akan melakukan scaling menggunakan `StandardScaler()` karena .....  \n",
    "Lalu mengencode dengan `OneHotEncoder()` karena .....  \n",
    "Setelah itu dimasukkan ke dalam variabel preprocess untuk dilakukan transformasi menggunakan `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling and encoding in column transformer\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers= [\n",
    "        ('numerical', scaler, num_col),\n",
    "        ('categorical', encoder, cat_col)\n",
    "        ], \n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition using pipeline\n",
    "pipe_log = make_pipeline(preprocess, LogisticRegression())\n",
    "pipe_svc = make_pipeline(preprocess, SVC())\n",
    "pipe_knn = make_pipeline(preprocess, KNeighborsClassifier())\n",
    "pipe_nb = make_pipeline(preprocess, GaussianNB())\n",
    "pipe_dt = make_pipeline(preprocess, DecisionTreeClassifier(random_state=70))\n",
    "pipe_rf = make_pipeline(preprocess, RandomForestClassifier(random_state=70))\n",
    "pipe_ada = make_pipeline(preprocess, AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define cross val for each pipeline\n",
    "cv_log = cross_val_score(pipe_log, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_svc = cross_val_score(pipe_svc, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_knn = cross_val_score(pipe_knn, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_nb = cross_val_score(pipe_nb, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_dt = cross_val_score(pipe_dt, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_rf = cross_val_score(pipe_rf, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_ada = cross_val_score(pipe_ada, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log\n",
      "f1-score - All - Cross Validation : [0.76190476 0.87179487 0.92682927 0.75675676 0.76923077]\n",
      "f1-score - Mean - Cross Validation : 0.8173032855959684\n",
      "f1-score - Std - Cross Validation : 0.06929807971867406\n",
      "f1-score - Range of test set : 0.7480052058772944 - 0.8866013653146425\n",
      "--------------------------------------------------\n",
      "svc\n",
      "f1-score - All - Cross Validation : [0.79069767 0.86486486 0.8372093  0.66666667 0.76923077]\n",
      "f1-score - Mean - Cross Validation : 0.7857338555012974\n",
      "f1-score - Std - Cross Validation : 0.06838921710377249\n",
      "f1-score - Range of test set : 0.7173446383975248 - 0.8541230726050699\n",
      "--------------------------------------------------\n",
      "knn\n",
      "f1-score - All - Cross Validation : [0.77272727 0.85714286 0.7804878  0.73684211 0.73684211]\n",
      "f1-score - Mean - Cross Validation : 0.7768084290548989\n",
      "f1-score - Std - Cross Validation : 0.0439964272515176\n",
      "f1-score - Range of test set : 0.7328120018033812 - 0.8208048563064165\n",
      "--------------------------------------------------\n",
      "nb\n",
      "f1-score - All - Cross Validation : [0.37037037 0.46153846 0.17391304 0.37037037 0.4516129 ]\n",
      "f1-score - Mean - Cross Validation : 0.3655610297966539\n",
      "f1-score - Std - Cross Validation : 0.10333615291641468\n",
      "f1-score - Range of test set : 0.2622248768802392 - 0.46889718271306857\n",
      "--------------------------------------------------\n",
      "dt\n",
      "f1-score - All - Cross Validation : [0.76190476 0.85       0.85714286 0.76923077 0.78947368]\n",
      "f1-score - Mean - Cross Validation : 0.805550414497783\n",
      "f1-score - Std - Cross Validation : 0.04029904879454541\n",
      "f1-score - Range of test set : 0.7652513657032376 - 0.8458494632923284\n",
      "--------------------------------------------------\n",
      "rf\n",
      "f1-score - All - Cross Validation : [0.75       0.92682927 0.92307692 0.7804878  0.82051282]\n",
      "f1-score - Mean - Cross Validation : 0.840181363352095\n",
      "f1-score - Std - Cross Validation : 0.0727494110621427\n",
      "f1-score - Range of test set : 0.7674319522899523 - 0.9129307744142378\n",
      "--------------------------------------------------\n",
      "ada\n",
      "f1-score - All - Cross Validation : [0.73170732 0.85       0.87179487 0.85       0.78947368]\n",
      "f1-score - Mean - Cross Validation : 0.8185951746157137\n",
      "f1-score - Std - Cross Validation : 0.051381504233608835\n",
      "f1-score - Range of test set : 0.7672136703821049 - 0.8699766788493226\n",
      "--------------------------------------------------\n",
      "Best Model: rf\n",
      "Cross Val Mean from best model: 0.840181363352095\n"
     ]
    }
   ],
   "source": [
    "# Finding best model based on Cross_val_score (mean)\n",
    "\n",
    "name_model = []\n",
    "cv_scores = 0\n",
    "\n",
    "for cv,name in zip([cv_log, cv_svc, cv_knn, cv_nb, cv_dt, cv_rf, cv_ada],\n",
    "                   ['log', 'svc', 'knn', 'nb', 'dt', 'rf', 'ada']):\n",
    "    print(name)\n",
    "    print('f1-score - All - Cross Validation :', cv)\n",
    "    print('f1-score - Mean - Cross Validation :', cv.mean())\n",
    "    print('f1-score - Std - Cross Validation :', cv.std())\n",
    "    print('f1-score - Range of test set :', (cv.mean()-cv.std()), '-',(cv.mean()+cv.std()))\n",
    "    print('-'*50)\n",
    "    if cv.mean() > cv_scores:\n",
    "        cv_scores = cv.mean()\n",
    "        name_model = name\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(f'Best Model: {name_model}')\n",
    "print(f'Cross Val Mean from best model: {cv_scores}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
